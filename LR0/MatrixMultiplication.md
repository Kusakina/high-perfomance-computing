В данной лабораторной работе необходимо было выполнить умножение матриц [код](https://colab.research.google.com/drive/11qTyR7TqO-PJ3ncNcGIMyalaBNN2H8xz?usp=sharing) на cpu gpu, произвести замеры времени работ и провести анализ полученных результатов.
Исходный код был написан на языке программирования Python, для использования графического процессора применялась библиотека Numba.

# Ход работы:
1. Генерируем матрицы с рандомными целочислкенными значениями (от 0 до 3), заданной размерности (`def generateRandomMatrix`)
2. Производим умножение матриц на центральном процессоре при помощи (`@`), так как написанная функция умножения (`def cpuMatrixMultiply`) матриц работает очень долго.
3. Производим подсчет времени работы
4. Производим умножение матриц на графическом процессоре при помощи (`def gpuMatrixMultiply`)
5. Производим подсчет времени работы
6. Сравниваем результаты умножения (равенство двух матриц, полученных разными способами)
7. Усредняем результаты для каждой размерности матриц
8. Строим графики зависимости времени работы программы от размерности матрицы (для CPU и GPU)
9. Строим графики зависимости ускорения программы от размерности матрицы

Распараллеливанию подлежали математические операции (умножение и сложение) для поиска элементов результирующей матрицы. Для этого данные двух входных матриц передавались
на девайс, чтобы все созданные нити могли выполнить функцию ядра (`def matmul`) над данными. Полученные данные возвращались обратно на хост.
# Полученные результаты:
![image](https://github.com/Kusakina/high-perfomance-computing/assets/74459357/1a388dd0-5507-45d0-8e14-151c2f150694)
![image](https://github.com/Kusakina/high-perfomance-computing/assets/74459357/b7af4980-6bfd-456f-97f8-2bcbc2e44b58)
